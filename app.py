#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLMjuice Web Application
ä¸€ä¸ªç”¨äºPDFæ–‡çŒ®å¤„ç†å’Œé—®ç­”å¯¹ç”Ÿæˆçš„Webç•Œé¢
é›†æˆOCRã€æ•°æ®å¤„ç†å’Œè®­ç»ƒæ•°æ®ç”ŸæˆåŠŸèƒ½
"""

import os
import json
import threading
import time
import subprocess
import shutil
import asyncio
import random
from pathlib import Path
from datetime import datetime
from flask import Flask, render_template, request, jsonify, send_file, redirect, url_for, flash
from werkzeug.utils import secure_filename
import logging
from dotenv import load_dotenv, set_key

# åˆå§‹åŒ–Flaskåº”ç”¨
app = Flask(__name__)
app.secret_key = 'llmjuice_secret_key_2025'
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max file size

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('webapp.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
processing_status = {
    'current_step': '',
    'progress': 0,
    'total_steps': 0,
    'message': '',
    'is_processing': False,
    'start_time': None,
    'files_processed': [],
    'error': None
}

# ç¡®ä¿ç›®å½•å­˜åœ¨
def ensure_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    directories = [
        'data/pdf',
        'data/markdown',
        'data/split',
        'data/train_data',
        'uploads',
        'static/uploads'
    ]

    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)

def get_processing_steps():
    """è·å–å¤„ç†æ­¥éª¤"""
    return [
        {
            'id': 'upload',
            'name': 'PDFä¸Šä¼ ',
            'description': 'ä¸Šä¼ PDFæ–‡ä»¶åˆ°å¤„ç†é˜Ÿåˆ—'
        },
        {
            'id': 'ocr',
            'name': 'OCRè¯†åˆ«',
            'description': 'ä½¿ç”¨MinerUè¿›è¡ŒOCRæ–‡å­—è¯†åˆ«'
        },
        {
            'id': 'split',
            'name': 'æ•°æ®åˆ‡åˆ†',
            'description': 'å°†è¯†åˆ«ç»“æœåˆ‡åˆ†æˆå°ç‰‡æ®µ'
        },
        {
            'id': 'generate',
            'name': 'ç”Ÿæˆé—®ç­”å¯¹',
            'description': 'åŸºäºç‰‡æ®µç”Ÿæˆè®­ç»ƒæ•°æ® (æœ€è€—æ—¶)'
        },
        {
            'id': 'complete',
            'name': 'å¤„ç†å®Œæˆ',
            'description': 'æ‰€æœ‰å¤„ç†æ­¥éª¤å®Œæˆ'
        }
    ]

def get_generation_params():
    """è·å–é—®ç­”å¯¹ç”Ÿæˆå‚æ•°"""
    # å¼ºåˆ¶é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡ï¼Œè¦†ç›–å·²å­˜åœ¨çš„ç¯å¢ƒå˜é‡
    load_dotenv(override=True)

    # è·å–ç‰‡æ®µæ€»æ•°ç”¨äºè®¡ç®—æœ€å¤§ç”Ÿæˆæ•°é‡
    current_max_count = 1
    try:
        processed_data_path = Path('data/split/processed_data.jsonl')
        if processed_data_path.exists():
            with open(processed_data_path, 'r', encoding='utf-8') as f:
                current_max_count = sum(1 for line in f if line.strip())
    except:
        current_max_count = 1

    # è·å–ç”Ÿæˆæ¨¡å¼ï¼Œé»˜è®¤ä¸ºæ‰‹åŠ¨æ¨¡å¼
    generation_mode = os.getenv('GENERATION_MODE', 'manual').lower()

    # è·å–ç”¨æˆ·è®¾ç½®çš„ç”Ÿæˆæ•°é‡
    user_num_chat = os.getenv('NUM_CHAT_TO_GENERATE')

    # æ ¹æ®æ¨¡å¼ç¡®å®šç”Ÿæˆæ•°é‡å’Œæ˜¾ç¤ºçš„æœ€å¤§å€¼
    if generation_mode == 'auto':
        # è‡ªåŠ¨æ¨¡å¼ï¼šæ‰¿è¯ºå¤„ç†æ‰€æœ‰åˆ‡ç‰‡ï¼Œä½¿ç”¨ç‰¹æ®Šå€¼è¡¨ç¤ºåŠ¨æ€æœ€å¤§å€¼
        num_chat = -1  # -1 è¡¨ç¤º"å¤„ç†æ‰€æœ‰åˆ‡ç‰‡"
        display_max_count = 999999  # å‰ç«¯æ˜¾ç¤ºçš„å¤§æ•°å€¼
        display_text = "è‡ªåŠ¨æœ€å¤§åŒ– (å°†å¤„ç†æ‰€æœ‰åˆ‡ç‰‡)"
    else:
        # æ‰‹åŠ¨æ¨¡å¼ï¼šåŸºäºå½“å‰å®é™…åˆ‡ç‰‡æ•°é‡
        display_max_count = current_max_count
        display_text = f"å½“å‰æœ€å¤§å€¼: {current_max_count}"

        # è§£æç”¨æˆ·è®¾ç½®çš„æ•°é‡
        if user_num_chat and user_num_chat.lower() == 'max':
            num_chat = current_max_count
        else:
            try:
                num_chat = int(user_num_chat) if user_num_chat else current_max_count
            except (ValueError, TypeError):
                num_chat = current_max_count

    return {
        'max_requests_per_minute': int(os.getenv('MAX_REQUESTS_PER_MINUTE', '30')),
        'num_chat_to_generate': num_chat,
        'max_chat_to_generate': display_max_count,
        'current_max_chat_to_generate': current_max_count,  # å®é™…å½“å‰åˆ‡ç‰‡æ•°
        'generation_mode': generation_mode,
        'display_text': display_text,
        'num_turn_ratios': [1, 0, 0, 0, 0]  # å›ºå®š1è½®å¯¹è¯
    }

def save_generation_params(params):
    """ä¿å­˜é—®ç­”å¯¹ç”Ÿæˆå‚æ•°åˆ°ç¯å¢ƒå˜é‡"""
    try:
        env_file = Path('.env')
        if not env_file.exists():
            env_file.touch()

        # éªŒè¯å‚æ•°
        required_keys = ['max_requests_per_minute', 'num_chat_to_generate', 'max_chat_to_generate']
        for key in required_keys:
            if key not in params:
                logger.error(f"ç¼ºå°‘å¿…éœ€å‚æ•°: {key}")
                return False

        # åªä¿å­˜ç”¨æˆ·å¯é…ç½®çš„å‚æ•°
        set_key('.env', 'MAX_REQUESTS_PER_MINUTE', str(params['max_requests_per_minute']))

        # ä¿å­˜ç”Ÿæˆæ¨¡å¼
        generation_mode = params.get('generation_mode', 'manual')
        set_key('.env', 'GENERATION_MODE', generation_mode)

        # æ ¹æ®æ¨¡å¼ä¿å­˜ç”Ÿæˆæ•°é‡
        if generation_mode == 'auto':
            # è‡ªåŠ¨æ¨¡å¼ï¼šä¿å­˜ä¸º'max'ï¼Œè¡¨ç¤ºå¤„ç†æ‰€æœ‰åˆ‡ç‰‡
            set_key('.env', 'NUM_CHAT_TO_GENERATE', 'max')
        else:
            # æ‰‹åŠ¨æ¨¡å¼ï¼šä¿å­˜å®é™…å€¼æˆ–'max'
            if params['num_chat_to_generate'] == -1:
                set_key('.env', 'NUM_CHAT_TO_GENERATE', 'max')
            elif params['num_chat_to_generate'] == params['max_chat_to_generate']:
                set_key('.env', 'NUM_CHAT_TO_GENERATE', 'max')
            else:
                set_key('.env', 'NUM_CHAT_TO_GENERATE', str(params['num_chat_to_generate']))

        # å›ºå®š1è½®å¯¹è¯æ¯”ä¾‹
        set_key('.env', 'NUM_TURN_RATIOS', '1,0,0,0,0')

        # é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡ä»¥ç«‹å³ç”Ÿæ•ˆï¼Œå¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„ç¯å¢ƒå˜é‡
        load_dotenv(override=True)
        logger.info(f"æˆåŠŸä¿å­˜ç”Ÿæˆå‚æ•°: max_requests={params['max_requests_per_minute']}, num_chat={params['num_chat_to_generate']}")
        return True

    except Exception as e:
        logger.error(f"ä¿å­˜ç”Ÿæˆå‚æ•°å¤±è´¥: {e}")
        logger.error(f"å‚æ•°è¯¦æƒ…: {params}")
        return False

def get_env_config():
    """è·å–ç¯å¢ƒå˜é‡é…ç½®"""
    load_dotenv()
    return {
        'MinerU_KEY': os.getenv('MinerU_KEY', ''),
        'API_KEY': os.getenv('API_KEY', ''),
        'BASE_URL': os.getenv('BASE_URL', ''),
        'MODEL_NAME': os.getenv('MODEL_NAME', '')
    }

def save_env_config(config):
    """ä¿å­˜ç¯å¢ƒå˜é‡é…ç½®åˆ°.envæ–‡ä»¶"""
    try:
        env_file = Path('.env')
        if not env_file.exists():
            env_file.touch()

        for key, value in config.items():
            set_key('.env', key, value)

        # é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
        return False

def get_file_list(directory, file_type='pdf'):
    """è·å–æŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶åˆ—è¡¨"""
    try:
        dir_path = Path(f'data/{directory}')
        if not dir_path.exists():
            return []

        files = []
        for file_path in dir_path.rglob(f'*.{file_type}'):
            stat = file_path.stat()
            files.append({
                'name': file_path.name,
                'path': str(file_path),
                'size': f"{stat.st_size / 1024 / 1024:.2f} MB",
                'modified': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                'relative_path': str(file_path.relative_to('data'))
            })

        return sorted(files, key=lambda x: x['modified'], reverse=True)
    except Exception as e:
        logger.error(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
        return []

def get_processing_results():
    """è·å–å¤„ç†ç»“æœæ–‡ä»¶"""
    results = {
        'markdown_files': get_file_list('markdown', 'md'),
        'split_files': get_file_list('split', 'jsonl'),
        'train_files': get_file_list('train_data', 'jsonl')
    }

    # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆçš„è®­ç»ƒæ•°æ®æ–‡ä»¶
    train_final_path = Path('data/train_data/train_final.jsonl')
    if train_final_path.exists():
        stat = train_final_path.stat()
        results['train_final'] = {
            'name': 'train_final.jsonl',
            'path': str(train_final_path),
            'size': f"{stat.st_size / 1024 / 1024:.2f} MB",
            'modified': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
            'download_url': '/download/train_data/train_final.jsonl'
        }

    return results

def run_processing_script(script_name, *args):
    """è¿è¡Œå¤„ç†è„šæœ¬"""
    try:
        script_path = Path(f"{script_name}")
        if not script_path.exists():
            raise FileNotFoundError(f"è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {script_name}")

        cmd = ['python', str(script_path)] + list(args)
        logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")

        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8',
            timeout=3600  # 1å°æ—¶è¶…æ—¶
        )

        if result.returncode != 0:
            error_msg = f"è„šæœ¬æ‰§è¡Œå¤±è´¥: {result.stderr}"
            logger.error(error_msg)
            raise Exception(error_msg)

        logger.info(f"è„šæœ¬æ‰§è¡ŒæˆåŠŸ: {result.stdout}")
        return True

    except subprocess.TimeoutExpired:
        error_msg = f"è„šæœ¬æ‰§è¡Œè¶…æ—¶: {script_name}"
        logger.error(error_msg)
        raise Exception(error_msg)
    except Exception as e:
        logger.error(f"æ‰§è¡Œè„šæœ¬æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise

def processing_worker():
    """åå°å¤„ç†å·¥ä½œçº¿ç¨‹"""
    try:
        processing_status['is_processing'] = True
        processing_status['start_time'] = datetime.now()
        processing_status['error'] = None

        steps = get_processing_steps()
        total_steps = len(steps) - 1  # å‡å»completeæ­¥éª¤
        current_step_index = 0

        # æ£€æŸ¥é…ç½®
        config = get_env_config()
        if not all([config['MinerU_KEY'], config['API_KEY']]):
            raise Exception("è¯·å…ˆé…ç½®APIå¯†é’¥")

        # è·å–ç”Ÿæˆå‚æ•°
        gen_params = get_generation_params()
        logger.info(f"ä½¿ç”¨ç”Ÿæˆå‚æ•°: {gen_params}")

        # æ­¥éª¤1: OCRå¤„ç†
        processing_status['current_step'] = 'ocr'
        processing_status['progress'] = (current_step_index / total_steps) * 100
        processing_status['message'] = 'æ­£åœ¨è¿›è¡ŒOCRè¯†åˆ«...'

        run_processing_script('batch_ocr.py')
        current_step_index += 1

        # æ­¥éª¤2: æ•°æ®åˆ‡åˆ†
        processing_status['current_step'] = 'split'
        processing_status['progress'] = (current_step_index / total_steps) * 100
        processing_status['message'] = 'æ­£åœ¨è¿›è¡Œæ•°æ®åˆ‡åˆ†...'

        run_processing_script('data_split.py')
        current_step_index += 1

        # æ­¥éª¤3: ç”Ÿæˆé—®ç­”å¯¹ (ä½¿ç”¨å›ºå®šå‚æ•°)
        processing_status['current_step'] = 'generate'
        processing_status['progress'] = (current_step_index / total_steps) * 100
        processing_status['message'] = f'æ­£åœ¨ç”Ÿæˆé—®ç­”å¯¹ (å¹¶å‘: {gen_params["max_requests_per_minute"]}/åˆ†é’Ÿ, ç”Ÿæˆæ•°é‡: {gen_params["num_chat_to_generate"]})...'

        # æ„å»ºå‘½ä»¤å‚æ•° - ä½¿ç”¨å›ºå®šå‚æ•°
        cmd_args = [
            '--reference_filepaths', './data/split/processed_data.jsonl',
            '--save_filepath', './data/train_data/train_final.jsonl',
            '--num_chat_to_generate', str(gen_params['num_chat_to_generate']),
            '--language', 'zh',
            '--num_turn_ratios', '1', '0', '0', '0', '0'
        ]

        # åªæœ‰ç”¨æˆ·è®¾ç½®äº†å¹¶å‘æ•°æ‰æ·»åŠ å¹¶å‘å‚æ•°
        if gen_params['max_requests_per_minute'] != 30:  # 30æ˜¯æ–°çš„é»˜è®¤å€¼
            cmd_args.extend([
                '--max_requests_per_minute', str(gen_params['max_requests_per_minute'])
            ])

        run_processing_script('data_generatefinal.py', *cmd_args)
        current_step_index += 1

        # å®Œæˆ
        processing_status['current_step'] = 'complete'
        processing_status['progress'] = 100
        processing_status['message'] = 'ğŸ‰ æ‰€æœ‰å¤„ç†æ­¥éª¤å®Œæˆï¼'
        processing_status['is_processing'] = False

        logger.info("æ‰€æœ‰å¤„ç†æ­¥éª¤å®Œæˆ")

    except Exception as e:
        logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        processing_status['error'] = str(e)
        processing_status['message'] = f'âŒ å¤„ç†å¤±è´¥: {str(e)}'
        processing_status['is_processing'] = False

# è·¯ç”±å®šä¹‰
@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html',
                         steps=get_processing_steps(),
                         config=get_env_config(),
                         generation_config=get_generation_params(),
                         results=get_processing_results())

@app.route('/config', methods=['GET', 'POST'])
def config():
    """é…ç½®é¡µé¢"""
    if request.method == 'POST':
        config_data = {
            'MinerU_KEY': request.form.get('MinerU_KEY', ''),
            'API_KEY': request.form.get('API_KEY', ''),
            'BASE_URL': request.form.get('BASE_URL', ''),
            'MODEL_NAME': request.form.get('MODEL_NAME', '')
        }

        if save_env_config(config_data):
            flash('é…ç½®ä¿å­˜æˆåŠŸï¼', 'success')
        else:
            flash('é…ç½®ä¿å­˜å¤±è´¥ï¼', 'error')

        return redirect(url_for('config'))

    return render_template('config.html', config=get_env_config())

@app.route('/generation_config', methods=['GET', 'POST'])
def generation_config():
    """é—®ç­”å¯¹ç”Ÿæˆå‚æ•°é…ç½®é¡µé¢"""
    if request.method == 'POST':
        try:
            # è·å–è¡¨å•æ•°æ®
            max_requests = int(request.form.get('max_requests_per_minute', 30))
            generation_mode = request.form.get('generation_mode', 'manual').lower()
            num_chat = request.form.get('num_chat_to_generate', 'max')

            # è·å–å½“å‰æœ€å¤§ç”Ÿæˆæ•°é‡
            current_params = get_generation_params()
            max_chat = current_params['max_chat_to_generate']

            # æ ¹æ®ç”Ÿæˆæ¨¡å¼ç¡®å®šç”Ÿæˆæ•°é‡
            if generation_mode == 'auto':
                # è‡ªåŠ¨æ¨¡å¼ï¼šä½¿ç”¨ç‰¹æ®Šå€¼ -1 è¡¨ç¤º"å¤„ç†æ‰€æœ‰åˆ‡ç‰‡"
                num_chat_value = -1
            else:
                # æ‰‹åŠ¨æ¨¡å¼ï¼šè§£æç”¨æˆ·è¾“å…¥çš„æ•°é‡
                if num_chat == 'max':
                    num_chat_value = max_chat
                else:
                    num_chat_value = int(num_chat)
                    if num_chat_value > max_chat:
                        num_chat_value = max_chat
                    elif num_chat_value < 1:
                        num_chat_value = 1

            # æ„å»ºå‚æ•°å­—å…¸
            params = {
                'max_requests_per_minute': max_requests,
                'num_chat_to_generate': num_chat_value,
                'max_chat_to_generate': max_chat,
                'generation_mode': generation_mode,
                'num_turn_ratios': [1, 0, 0, 0, 0]  # å›ºå®š1è½®å¯¹è¯
            }

            if save_generation_params(params):
                flash('ç”Ÿæˆå‚æ•°ä¿å­˜æˆåŠŸï¼', 'success')
            else:
                flash('ç”Ÿæˆå‚æ•°ä¿å­˜å¤±è´¥ï¼', 'error')

        except ValueError as e:
            flash(f'å‚æ•°æ ¼å¼é”™è¯¯: {str(e)}', 'error')
        except Exception as e:
            flash(f'ä¿å­˜å¤±è´¥: {str(e)}', 'error')

        return redirect(url_for('generation_config'))

    return render_template('generation_config.html', params=get_generation_params())

@app.route('/upload', methods=['POST'])
def upload_file():
    """æ–‡ä»¶ä¸Šä¼ """
    if 'files' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400

    files = request.files.getlist('files')
    if not files or files[0].filename == '':
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400

    uploaded_files = []
    pdf_dir = Path('data/pdf')
    pdf_dir.mkdir(parents=True, exist_ok=True)

    for file in files:
        if file and file.filename.lower().endswith('.pdf'):
            filename = secure_filename(file.filename)
            file_path = pdf_dir / filename

            # é¿å…æ–‡ä»¶åå†²çª
            counter = 1
            original_name = filename
            while file_path.exists():
                name_parts = original_name.rsplit('.', 1)
                if len(name_parts) == 2:
                    filename = f"{name_parts[0]}_{counter}.{name_parts[1]}"
                else:
                    filename = f"{original_name}_{counter}"
                file_path = pdf_dir / filename
                counter += 1

            file.save(file_path)
            uploaded_files.append(filename)

    return jsonify({
        'success': True,
        'files': uploaded_files,
        'message': f'æˆåŠŸä¸Šä¼  {len(uploaded_files)} ä¸ªPDFæ–‡ä»¶'
    })

@app.route('/files')
def get_files():
    """è·å–æ–‡ä»¶åˆ—è¡¨"""
    pdf_files = get_file_list('pdf', 'pdf')
    return jsonify({'files': pdf_files})

@app.route('/process', methods=['POST'])
def start_processing():
    """å¼€å§‹å¤„ç†"""
    if processing_status['is_processing']:
        return jsonify({'error': 'æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç­‰å¾…å½“å‰å¤„ç†å®Œæˆ'}), 400

    # æ£€æŸ¥æ˜¯å¦æœ‰PDFæ–‡ä»¶
    pdf_files = get_file_list('pdf', 'pdf')
    if not pdf_files:
        return jsonify({'error': 'æ²¡æœ‰æ‰¾åˆ°PDFæ–‡ä»¶ï¼Œè¯·å…ˆä¸Šä¼ PDFæ–‡ä»¶'}), 400

    # æ£€æŸ¥é…ç½®
    config = get_env_config()
    if not all([config['MinerU_KEY'], config['API_KEY']]):
        return jsonify({'error': 'è¯·å…ˆé…ç½®APIå¯†é’¥'}), 400

    # é‡ç½®çŠ¶æ€
    processing_status.update({
        'current_step': '',
        'progress': 0,
        'message': 'å¼€å§‹å¤„ç†...',
        'is_processing': True,
        'start_time': None,
        'files_processed': [],
        'error': None
    })

    # å¯åŠ¨åå°å¤„ç†çº¿ç¨‹
    thread = threading.Thread(target=processing_worker)
    thread.daemon = True
    thread.start()

    return jsonify({'success': True, 'message': 'å¤„ç†å·²å¼€å§‹'})

@app.route('/status')
def get_status():
    """è·å–å¤„ç†çŠ¶æ€"""
    status = processing_status.copy()
    if status['start_time']:
        status['elapsed_time'] = str(datetime.now() - status['start_time']).split('.')[0]

    # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
    status['files'] = {
        'pdf_count': len(get_file_list('pdf', 'pdf')),
        'results': get_processing_results()
    }

    return jsonify(status)

@app.route('/download/<path:filename>')
def download_file(filename):
    """ä¸‹è½½æ–‡ä»¶"""
    try:
        file_path = Path('data') / filename
        if not file_path.exists():
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return jsonify({'error': f'æ–‡ä»¶ä¸å­˜åœ¨: {filename}'}), 404

        logger.info(f"ä¸‹è½½æ–‡ä»¶: {file_path}")
        return send_file(file_path, as_attachment=True, download_name=file_path.name)
    except Exception as e:
        logger.error(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': 'ä¸‹è½½å¤±è´¥'}), 500

@app.route('/delete_file/<path:filename>', methods=['POST'])
def delete_file(filename):
    """åˆ é™¤æ–‡ä»¶"""
    try:
        file_path = Path('data') / filename
        if file_path.exists():
            file_path.unlink()
            return jsonify({'success': True, 'message': 'æ–‡ä»¶åˆ é™¤æˆåŠŸ'})
        else:
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': 'åˆ é™¤å¤±è´¥'}), 500

@app.route('/api/generation_config')
def api_generation_config():
    """è·å–ç”Ÿæˆå‚æ•°é…ç½®API"""
    try:
        return jsonify(get_generation_params())
    except Exception as e:
        logger.error(f"è·å–ç”Ÿæˆå‚æ•°å¤±è´¥: {e}")
        return jsonify({'error': 'è·å–å‚æ•°å¤±è´¥'}), 500

# é”™è¯¯å¤„ç†
@app.errorhandler(413)
def too_large(e):
    return jsonify({'error': 'æ–‡ä»¶å¤ªå¤§ï¼Œè¯·ä¸Šä¼ å°äº50MBçš„æ–‡ä»¶'}), 413

@app.errorhandler(404)
def not_found(e):
    return render_template('404.html'), 404

@app.errorhandler(500)
def server_error(e):
    return render_template('500.html'), 500

# è¯„ä¼°é¡µé¢è·¯ç”±
@app.route('/evaluation')
def evaluation():
    """LLMå¾®è°ƒæ•ˆæœå¯¹æ¯”è¯„æµ‹é¡µé¢"""
    return render_template('evaluation.html')

# è¯„ä¼°ç›¸å…³API
@app.route('/api/dataset_info')
def get_dataset_info():
    """è·å–æ•°æ®é›†ä¿¡æ¯"""
    try:
        dataset_path = Path('./data/train_data/train_final.jsonl')
        if not dataset_path.exists():
            return jsonify({'error': 'æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨'})

        with open(dataset_path, 'r', encoding='utf-8') as f:
            total_pairs = sum(1 for line in f if line.strip())

        return jsonify({'total_pairs': total_pairs})
    except Exception as e:
        logger.error(f"è·å–æ•°æ®é›†ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# è¯„ä¼°ä»»åŠ¡ç®¡ç†
evaluation_tasks = {}

@app.route('/api/start_evaluation', methods=['POST'])
def start_evaluation():
    """å¯åŠ¨è¯„ä¼°ä»»åŠ¡"""
    try:
        config = request.json
        logger.info(f"æ”¶åˆ°è¯„ä¼°å¯åŠ¨è¯·æ±‚: {config}")

        # éªŒè¯é…ç½®
        required_fields = ['ft_model', 'base_model', 'judge_model', 'sample_count']
        for field in required_fields:
            if field not in config:
                logger.error(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return jsonify({'success': False, 'message': f'ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}'})

        # ç”Ÿæˆä»»åŠ¡ID
        task_id = f"eval_{int(time.time())}"
        logger.info(f"ç”Ÿæˆä»»åŠ¡ID: {task_id}")

        # åˆ›å»ºä»»åŠ¡
        from evaluation_engine import EvaluationTask
        task = EvaluationTask(task_id, config)
        evaluation_tasks[task_id] = task
        logger.info(f"ä»»åŠ¡å·²åˆ›å»ºï¼Œå½“å‰ä»»åŠ¡æ•°é‡: {len(evaluation_tasks)}")

        # å¼‚æ­¥å¯åŠ¨ä»»åŠ¡
        import threading

        def run_task():
            try:
                logger.info(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_id}")
                # åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºäº‹ä»¶å¾ªç¯
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(task.run())
                logger.info(f"ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {task_id}")
            except Exception as e:
                logger.error(f"è¯„ä¼°ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                task.status = 'failed'
                task.error = str(e)

        thread = threading.Thread(target=run_task)
        thread.daemon = True
        thread.start()
        logger.info(f"ä»»åŠ¡çº¿ç¨‹å·²å¯åŠ¨: {task_id}")

        return jsonify({'success': True, 'task_id': task_id})

    except Exception as e:
        logger.error(f"å¯åŠ¨è¯„ä¼°å¤±è´¥: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/api/evaluation_progress/<task_id>')
def get_evaluation_progress(task_id):
    """è·å–è¯„ä¼°è¿›åº¦"""
    try:
        logger.info(f"æŸ¥è¯¢ä»»åŠ¡è¿›åº¦: {task_id}, å½“å‰ä»»åŠ¡åˆ—è¡¨: {list(evaluation_tasks.keys())}")

        if task_id not in evaluation_tasks:
            logger.error(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

        task = evaluation_tasks[task_id]
        progress_data = {
            'status': task.status,
            'progress': task.progress,
            'current_step': task.current_step,
            'processed': task.processed,
            'total': task.total,
            'log_message': task.get_latest_log()
        }
        logger.info(f"è¿”å›è¿›åº¦æ•°æ®: {progress_data}")
        return progress_data

    except Exception as e:
        logger.error(f"è·å–è¿›åº¦å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/evaluation_results/<task_id>')
def get_evaluation_results(task_id):
    """è·å–è¯„ä¼°ç»“æœ"""
    try:
        if task_id not in evaluation_tasks:
            return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

        task = evaluation_tasks[task_id]
        if task.status != 'completed':
            return jsonify({'error': 'ä»»åŠ¡å°šæœªå®Œæˆ'}), 400

        return jsonify({
            'success': True,
            'results': task.results,
            'statistics': task.statistics
        })

    except Exception as e:
        logger.error(f"è·å–ç»“æœå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/recent_evaluation_results')
def get_recent_evaluation_results():
    """è·å–æœ€è¿‘çš„è¯„ä¼°ç»“æœ"""
    try:
        # æŸ¥æ‰¾æœ€è¿‘çš„è¯„ä¼°ç»“æœæ–‡ä»¶
        evaluate_dir = Path('./data/evaluate')
        if not evaluate_dir.exists():
            return jsonify({'success': False, 'message': 'æ²¡æœ‰æ‰¾åˆ°è¯„ä¼°ç»“æœç›®å½•'})

        # æŸ¥æ‰¾æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
        log_files = list(evaluate_dir.glob('evaluation_log_*.jsonl'))
        if not log_files:
            return jsonify({'success': False, 'message': 'æ²¡æœ‰æ‰¾åˆ°è¯„ä¼°ç»“æœæ–‡ä»¶'})

        latest_file = max(log_files, key=lambda f: f.stat().st_mtime)

        # è¯»å–ç»“æœ
        results = []
        with open(latest_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    results.append(json.loads(line))

        return jsonify({
            'success': True,
            'results': results,
            'file_name': latest_file.name
        })

    except Exception as e:
        logger.error(f"è·å–æœ€è¿‘ç»“æœå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/evaluation_config', methods=['GET'])
def get_evaluation_config():
    """è·å–è¯„ä¼°é…ç½®ï¼ˆå·²ä¿å­˜çš„ï¼‰"""
    try:
        load_dotenv()

        # ä»ç¯å¢ƒå˜é‡è¯»å–å·²ä¿å­˜çš„é…ç½®ä¿¡æ¯ï¼ˆä¸åŒ…æ‹¬API Keyï¼‰
        config = {
            'ft_model': {
                'api_url': os.getenv('FT_API_URL', ''),
                'model_name': os.getenv('FT_MODEL_NAME', '')
            },
            'base_model': {
                'api_url': os.getenv('BASE_API_URL', ''),
                'model_name': os.getenv('BASE_MODEL_NAME', '')
            },
            'judge_model': {
                'api_url': os.getenv('JUDGE_API_URL', os.getenv('BASE_URL', '')),  # å¤ç”¨ä¸»é…ç½®ä½œä¸ºåå¤‡
                'model_name': os.getenv('JUDGE_MODEL_NAME', os.getenv('MODEL_NAME', ''))
            }
        }
        return jsonify({'config': config})
    except Exception as e:
        logger.error(f"è·å–è¯„ä¼°é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/env_config', methods=['GET'])
def api_get_env_config():
    """è·å–.envé…ç½®"""
    try:
        load_dotenv()

        # è¯»å–.envä¸­çš„é…ç½®ï¼Œæ”¯æŒå¤šç§ç¯å¢ƒå˜é‡åç§°
        api_url = os.getenv('BASE_URL') or os.getenv('API_URL', '')
        api_key = os.getenv('API_KEY', '')
        model_name = os.getenv('MODEL_NAME', '')

        config = {
            'success': True,
            'api_url': api_url,
            'api_key': api_key,
            'model_name': model_name
        }

        return jsonify(config)
    except Exception as e:
        logger.error(f"è·å–.envé…ç½®å¤±è´¥: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/api/save_evaluation_config', methods=['POST'])
def save_evaluation_config():
    """ä¿å­˜è¯„ä¼°é…ç½®åˆ°.envæ–‡ä»¶"""
    try:
        data = request.json
        if not data:
            return jsonify({'success': False, 'message': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'}), 400

        # è¯»å–å½“å‰.envæ–‡ä»¶å†…å®¹
        env_path = '.env'
        env_content = ''
        if os.path.exists(env_path):
            with open(env_path, 'r', encoding='utf-8') as f:
                env_content = f.read()

        # ä¿å­˜æ‰€æœ‰æ¨¡å‹é…ç½®
        lines = env_content.split('\n')
        new_lines = []

        # æ›´æ–°æˆ–æ·»åŠ æ‰€æœ‰æ¨¡å‹é…ç½®
        for line in lines:
            if line.startswith('FT_API_URL='):
                new_lines.append(f"FT_API_URL={data.get('ft_model', {}).get('api_url', '')}")
            elif line.startswith('FT_API_KEY='):
                new_lines.append(f"FT_API_KEY={data.get('ft_model', {}).get('api_key', '')}")
            elif line.startswith('FT_MODEL_NAME='):
                new_lines.append(f"FT_MODEL_NAME={data.get('ft_model', {}).get('model_name', '')}")
            elif line.startswith('BASE_API_URL='):
                new_lines.append(f"BASE_API_URL={data.get('base_model', {}).get('api_url', '')}")
            elif line.startswith('BASE_API_KEY='):
                new_lines.append(f"BASE_API_KEY={data.get('base_model', {}).get('api_key', '')}")
            elif line.startswith('BASE_MODEL_NAME='):
                new_lines.append(f"BASE_MODEL_NAME={data.get('base_model', {}).get('model_name', '')}")
            elif line.startswith('JUDGE_API_URL='):
                new_lines.append(f"JUDGE_API_URL={data.get('judge_model', {}).get('api_url', '')}")
            elif line.startswith('JUDGE_API_KEY='):
                new_lines.append(f"JUDGE_API_KEY={data.get('judge_model', {}).get('api_key', '')}")
            elif line.startswith('JUDGE_MODEL_NAME='):
                new_lines.append(f"JUDGE_MODEL_NAME={data.get('judge_model', {}).get('model_name', '')}")
            else:
                new_lines.append(line)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³é…ç½®è¡Œï¼Œåœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ 
        config_keys = ['FT_API_URL', 'FT_API_KEY', 'FT_MODEL_NAME',
                      'BASE_API_URL', 'BASE_API_KEY', 'BASE_MODEL_NAME',
                      'JUDGE_API_URL', 'JUDGE_API_KEY', 'JUDGE_MODEL_NAME']
        existing_keys = []

        for line in new_lines:
            if '=' in line:
                existing_keys.append(line.split('=')[0])

        for key in config_keys:
            if key not in existing_keys:
                if key == 'FT_API_URL':
                    new_lines.append(f"FT_API_URL={data.get('ft_model', {}).get('api_url', '')}")
                elif key == 'FT_API_KEY':
                    new_lines.append(f"FT_API_KEY={data.get('ft_model', {}).get('api_key', '')}")
                elif key == 'FT_MODEL_NAME':
                    new_lines.append(f"FT_MODEL_NAME={data.get('ft_model', {}).get('model_name', '')}")
                elif key == 'BASE_API_URL':
                    new_lines.append(f"BASE_API_URL={data.get('base_model', {}).get('api_url', '')}")
                elif key == 'BASE_API_KEY':
                    new_lines.append(f"BASE_API_KEY={data.get('base_model', {}).get('api_key', '')}")
                elif key == 'BASE_MODEL_NAME':
                    new_lines.append(f"BASE_MODEL_NAME={data.get('base_model', {}).get('model_name', '')}")
                elif key == 'JUDGE_API_URL':
                    new_lines.append(f"JUDGE_API_URL={data.get('judge_model', {}).get('api_url', '')}")
                elif key == 'JUDGE_API_KEY':
                    new_lines.append(f"JUDGE_API_KEY={data.get('judge_model', {}).get('api_key', '')}")
                elif key == 'JUDGE_MODEL_NAME':
                    new_lines.append(f"JUDGE_MODEL_NAME={data.get('judge_model', {}).get('model_name', '')}")

        # å†™å…¥.envæ–‡ä»¶
        with open(env_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(new_lines))

        logger.info("è¯„ä¼°é…ç½®å·²ä¿å­˜åˆ°.envæ–‡ä»¶")
        return jsonify({'success': True, 'message': 'é…ç½®å·²ä¿å­˜'})

    except Exception as e:
        logger.error(f"ä¿å­˜è¯„ä¼°é…ç½®å¤±è´¥: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500


# åˆå§‹åŒ–
if __name__ == '__main__':
    ensure_directories()
    logger.info("LLMjuice Web Application å¯åŠ¨")
    logger.info("è®¿é—®åœ°å€: http://localhost:5000")

    app.run(host='0.0.0.0', port=5000, debug=True, threaded=True)