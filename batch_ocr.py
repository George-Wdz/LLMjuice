import os
import time
import requests
import json
import zipfile
import io
import urllib3
from pathlib import Path
from dotenv import load_dotenv

# ================= é…ç½®åŒºåŸŸ =================
# 1. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
token = os.getenv("MinerU_KEY")
if not token:
    print("âŒ é”™è¯¯: æœªåœ¨ .env æ–‡ä»¶ä¸­é…ç½® MinerU_KEY")
    exit(1)

# 2. è·¯å¾„é…ç½®
base_dir = Path(__file__).parent
pdf_dir = base_dir / "data" / "pdf"
md_dir = base_dir / "data" / "markdown"
md_dir.mkdir(parents=True, exist_ok=True)

# 3. ç½‘ç»œé…ç½® (WSL/ä»£ç†å…¼å®¹)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
headers = {
    "Authorization": f"Bearer {token}",
    "Content-Type": "application/json"
}

# ================= æ ¸å¿ƒåŠŸèƒ½å‡½æ•° =================

def get_files_to_process():
    """æ‰«æç›®å½•ï¼Œè·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶"""
    if not pdf_dir.exists():
        print(f"âŒ PDF ç›®å½•ä¸å­˜åœ¨: {pdf_dir}")
        return []

    pending_files = []
    print(f"ğŸ“‚ æ­£åœ¨æ‰«æç›®å½•: {pdf_dir} ...")
    
    for pdf_file in pdf_dir.glob("*.pdf"):
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒåç»“æœæ–‡ä»¶å¤¹æˆ–mdæ–‡ä»¶
        # ç°åœ¨çš„ä¸‹è½½é€»è¾‘æ˜¯å»ºç«‹å­æ–‡ä»¶å¤¹ï¼Œæ‰€ä»¥æˆ‘ä»¬æ£€æŸ¥å­æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
        result_folder = md_dir / pdf_file.stem
        
        if result_folder.exists() and any(result_folder.iterdir()):
            print(f"â© è·³è¿‡ (å·²è§£æ): {pdf_file.name}")
            continue
        
        pending_files.append(pdf_file)
        
    return pending_files

def upload_files(files_to_upload):
    """æ‰¹é‡ç”³è¯·é“¾æ¥å¹¶ä¸Šä¼ æ–‡ä»¶"""
    print(f"\nğŸš€ å¼€å§‹å¤„ç† {len(files_to_upload)} ä¸ªæ–°æ–‡ä»¶...")

    # 1. æ„é€ è¯·æ±‚å‚æ•°
    request_file_list = []
    for f in files_to_upload:
        request_file_list.append({
            "name": f.name,
            "data_id": f.stem 
        })

    # 2. ç”³è¯·ä¸Šä¼ é“¾æ¥
    url_get_links = "https://mineru.net/api/v4/file-urls/batch"
    payload = {
        "files": request_file_list,
        "model_version": "vlm"
    }

    try:
        print("ğŸ“¡ æ­£åœ¨ç”³è¯·ä¸Šä¼ é“¾æ¥...")
        res = requests.post(url_get_links, headers=headers, json=payload, verify=False)
        
        if res.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {res.text}")
            return None

        res_json = res.json()
        if res_json["code"] != 0:
            print(f"âŒ API é”™è¯¯: {res_json['msg']}")
            return None

        batch_id = res_json["data"]["batch_id"]
        file_urls = res_json["data"]["file_urls"]
        print(f"âœ… æ‰¹æ¬¡åˆ›å»ºæˆåŠŸ! Batch ID: {batch_id}")

        # 3. ä¸Šä¼ æ–‡ä»¶
        success_count = 0
        for i, upload_url in enumerate(file_urls):
            local_file_path = files_to_upload[i]
            print(f"â¬†ï¸  æ­£åœ¨ä¸Šä¼  ({i+1}/{len(file_urls)}): {local_file_path.name}")
            
            with open(local_file_path, "rb") as f:
                # PUT ä¸Šä¼ ï¼Œæ— éœ€ç‰¹å®š Header
                upload_res = requests.put(upload_url, data=f, verify=False)
                if upload_res.status_code == 200:
                    success_count += 1
                else:
                    print(f"   âŒ ä¸Šä¼ å¤±è´¥ (Status: {upload_res.status_code})")
        
        if success_count == 0:
            print("âŒ æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹ã€‚")
            return None
            
        return batch_id

    except Exception as e:
        print(f"âŒ ä¸Šä¼ é˜¶æ®µå‘ç”Ÿå¼‚å¸¸: {e}")
        return None

def monitor_and_download(batch_id):
    """è½®è¯¢çŠ¶æ€å¹¶ä¸‹è½½ç»“æœ"""
    url = f"https://mineru.net/api/v4/extract-results/batch/{batch_id}"
    print(f"\nğŸ” å¼€å§‹è½®è¯¢è§£æç»“æœ (Batch: {batch_id})")
    print("â³ ç³»ç»Ÿæ­£åœ¨è§£æä¸­ï¼Œè¯·ç¨å€™...")

    # è®°å½•å·²ä¸‹è½½çš„æ–‡ä»¶ï¼Œé¿å…é‡å¤ä¸‹è½½
    downloaded_files = set()

    while True:
        try:
            time.sleep(5) # æ¯5ç§’æŸ¥ä¸€æ¬¡
            res = requests.get(url, headers=headers, verify=False)
            
            if res.status_code != 200:
                print(f"âš ï¸ æŸ¥è¯¢è¯·æ±‚å¤±è´¥: {res.status_code}ï¼Œé‡è¯•ä¸­...")
                continue
            
            data = res.json()
            if data["code"] != 0:
                print(f"âŒ æŸ¥è¯¢è¿”å›é”™è¯¯: {data['msg']}")
                break
            
            extract_results = data["data"]["extract_result"]
            
            # ç»Ÿè®¡å½“å‰æ‰¹æ¬¡çš„çŠ¶æ€
            all_finished = True
            running_cnt = 0
            
            # ç®€å•è¿›åº¦æ¡æ˜¾ç¤º
            status_summary = []

            for item in extract_results:
                state = item["state"]
                fname = item["file_name"]
                
                if state == "running" or state == "pending" or state == "waiting-file":
                    all_finished = False
                    running_cnt += 1
                
                # å¦‚æœçŠ¶æ€æ˜¯ done ä¸” è¿˜æ²¡ä¸‹è½½è¿‡ï¼Œç«‹å³ä¸‹è½½
                if state == "done" and fname not in downloaded_files:
                    print(f"\nâœ… æ£€æµ‹åˆ°å®Œæˆ: {fname}ï¼Œæ­£åœ¨ä¸‹è½½...")
                    if download_single_file(item):
                        downloaded_files.add(fname)
                
                # å¦‚æœå¤±è´¥äº†
                if state == "failed" and fname not in downloaded_files:
                    print(f"\nâŒ è§£æå¤±è´¥: {fname} (åŸå› : {item.get('err_msg')})")
                    downloaded_files.add(fname) # æ ‡è®°ä¸ºå·²å¤„ç†ï¼Œä¸å†æŠ¥é”™

            # æ‰“å°ç®€ç•¥è¿›åº¦
            print(f"\râ³ å‰©ä½™ä»»åŠ¡: {running_cnt} ä¸ªæ­£åœ¨å¤„ç†...", end="")

            if all_finished:
                print("\n\nğŸ‰ å½“å‰æ‰¹æ¬¡æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæ¯•ï¼")
                break

        except KeyboardInterrupt:
            print("\nğŸ›‘ ç”¨æˆ·æ‰‹åŠ¨åœæ­¢è½®è¯¢ã€‚")
            break
        except Exception as e:
            print(f"\nâŒ è½®è¯¢å¼‚å¸¸: {e}")
            break

def download_single_file(item_data):
    """ä¸‹è½½å•ä¸ªæ–‡ä»¶çš„ZIPå¹¶è§£å‹"""
    try:
        zip_url = item_data.get("full_zip_url")
        file_name = item_data.get("file_name")
        
        if not zip_url:
            return False

        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼šdata/markdown/æ–‡ä»¶å/
        folder_name = Path(file_name).stem
        output_folder = md_dir / folder_name
        output_folder.mkdir(parents=True, exist_ok=True)

        # ä¸‹è½½
        zip_res = requests.get(zip_url, verify=False)
        
        # è§£å‹
        with zipfile.ZipFile(io.BytesIO(zip_res.content)) as z:
            z.extractall(output_folder)
            
        print(f"   ğŸ’¾ å·²ä¿å­˜åˆ°: {output_folder}")
        return True
    except Exception as e:
        print(f"   âŒ ä¸‹è½½è§£å‹å‡ºé”™: {e}")
        return False

# ================= ä¸»ç¨‹åºå…¥å£ =================

if __name__ == "__main__":
    # 1. è·å–éœ€è¦å¤„ç†çš„æ–‡ä»¶
    files = get_files_to_process()
    
    if not files:
        print("ğŸ˜´ æ²¡æœ‰å‘ç°æ–°æ–‡ä»¶ï¼Œç¨‹åºé€€å‡ºã€‚")
    else:
        # 2. ä¸Šä¼ æ–‡ä»¶å¹¶è·å– Batch ID
        batch_id = upload_files(files)
        
        if batch_id:
            # 3. å¦‚æœä¸Šä¼ æˆåŠŸï¼Œç«‹å³å¼€å§‹è½®è¯¢ä¸‹è½½
            # ç­‰å¾…å‡ ç§’è®©æœåŠ¡å™¨ååº”ä¸€ä¸‹
            time.sleep(2)
            monitor_and_download(batch_id)